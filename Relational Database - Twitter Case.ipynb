{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "Twitter is a massive platform.  There are 300+ million users on Twitter, and it is a source of information for current events, social movements and, financial information.  It has been shown in a number of cases that information from Twitter can mobilize a large number of individuals.  From #blacklivesmatter to other forms of *hashtag* activism, social media can play an important role in informing and mobilizing individuals.\n",
    "\n",
    "This same activity can be extended to financial information.  The introduction of \"cashtags\" to twitter has allowed individuals to connect and discuss stocks, but it has also given stock promoters a method for promoting low value stocks, to \"pump and dump\".  Some researchers have analyzed the use of cashtags on Twitter.  We will use a similar method to look at the data, but we will ask a slightly different question.\n",
    "\n",
    "#### Raw Data source\n",
    "I document the source of ticker data below.  The tweet data we use here comes from a dataset used in Cresci *et al* (2019) referenced above.  The data is available through Zenodo using the dataset's DOI: [10.5281/zenodo.2686861](https://doi.org/10.5281/zenodo.2686861). \n",
    "\n",
    "The schema, tables, normalized data are created and loaded the database, which can be explored through pgAdmin.\n",
    "\n",
    "![ER Diagram](erdpgadmin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data dictionary\n",
    "\n",
    "### Twitter CashTag Records\n",
    "\n",
    "  * Title: Cashtag Piggybacking dataset - Twitter dataset enriched with financial data.\n",
    "  * URI: https://doi.org/10.5281/zenodo.2686861\n",
    "  * Keywords: cashtag, tweets, twitter, piggybacking, social, bot\n",
    "  * Publication Date: May 9, 2019\n",
    "  * Publisher: Zenodo\n",
    "  * Creator: Cresci, Stefano; Lillo, Fabrizio; Regoli, Daniele;  Tardelli, Serena; Tesconi, Maurizio\n",
    "  * Contact Point: N/A\n",
    "  * Spatial Coverage: Global\n",
    "  * Temporal Coverage: May - September 2017\n",
    "  * Language: Multilingual\n",
    "  * Date & Time Formats: \"Thu May 18 22:00:00 +0000 2017\"\n",
    "  * Data Version: 1.0\n",
    "  * Access Date: March 2, 2021\n",
    "\n",
    "### NYSE Stock Symbol Dataset\n",
    "\n",
    "  * Title: NYSE Symbol Directory\n",
    "  * URI: ftp://ftp.nasdaqtrader.com/SymbolDirectory/otherlisted.txt\n",
    "  * Keywords: stock symbols, nyse\n",
    "  * Publication Date: May 2, 2021\n",
    "  * Publisher: nasdaqtrader.com\n",
    "  * Creator: N/A\n",
    "  * Contact Point: N/A\n",
    "  * Spatial Coverage: Global\n",
    "  * Temporal Coverage: N/A\n",
    "  * Language: English\n",
    "  * Date & Time Formats: N/A\n",
    "  * Data Version: N/A\n",
    "  * Access Date: March 2, 2021\n",
    "\n",
    "### NYSE Stock Trading Data \n",
    "\n",
    "  * Title: Yahoo! Finance Data Daily Stock Price\n",
    "  * URI: https://finance.yahoo.com/\n",
    "  * Keywords: stock symbols, nyse, stock price\n",
    "  * Publication Date: N/A\n",
    "  * Publisher: Yahoo! Finance\n",
    "  * Creator: N/A\n",
    "  * Contact Point: N/A\n",
    "  * Spatial Coverage: New York, New York, USA\n",
    "  * Temporal Coverage: May - September 2017\n",
    "  * Language: English\n",
    "  * Date & Time Formats: 2003-02-19\n",
    "  * Data Version: N/A\n",
    "  * Access Date: March 2, 2021\n",
    "  \n",
    "  ## Data Model\n",
    "\n",
    "For each stock symbol, by day, we want the count of tweets that mention the symbol, the mean stock value on that day, and the name of the stock.\n",
    "\n",
    "Yahoo! Finance data is generated only for NYSE stocks, so we will ignore other stock symbols in the dataset.\n",
    "\n",
    "### NYSE Security Names\n",
    "\n",
    "| column | format | source | description | Validation |\n",
    "| ------ | ------ | ---------- | ------------ | ------------- |\n",
    "| symbolid | integer/serial | Unique numeric identifier | Unique integer |\n",
    "| nasdaqsymbol | text | NYSE Symbol Directory | Security abbreviation | Unique, alphanumeric, upper case, including (.-=+) |\n",
    "| securityname | text | NYSE Symbol Directory | Security name | Alphanumeric, unique   |\n",
    "\n",
    "### NYSE Stock Values\n",
    "\n",
    "| column | format | source | description | Validation |\n",
    "| ------ | ------ | ---------- | ------------ | ------------- |\n",
    "| symbolid | int | References securities | Integer link to the securities table. | FOREIGN KEY |\n",
    "| date | date | Yahoo! Finance | Date of stock values | Valid datetime (yyyy-MM-DD) |\n",
    "| volume | numeric |  Yahoo! Finance | volume of stock traded on date | Positive integer value |\n",
    "| open | float |  Yahoo! Finance | USD value of security at trading open | Positive float value |\n",
    "| close | float |  Yahoo! Finance | USD value of security at trading close | Positive float value |\n",
    "\n",
    "### Twitter Users\n",
    "\n",
    "| column | format | source | description | Validation |\n",
    "| ------ | ------ | ---------- | ------------ | ------------- |\n",
    "| userid | bigint | Twitter API | Unique numeric integer to identify a user | Positive integer |\n",
    "| username | text | Twitter API | Optional user name (not used currently) | Text string with valid twitter handle |\n",
    "\n",
    "### Tweets\n",
    "\n",
    "| column | format | source | description | Validation |\n",
    "| ------ | ------ | ---------- | ------------ | ------------- |\n",
    "| tweetid | bigint | Twitter API | Unique numeric ID for tweets | Positive integer |\n",
    "| userid | bigint | Twitter API | Unique numeric ID for users | FOREIGN KEY |\n",
    "| text | text | Twitter API | Text content of a Tweet | Valid text for tweet content |\n",
    "| createddate | datetime | Twitter API | Date with timestamp | Valid Datetime between May and September 2017 |\n",
    "\n",
    "### Retweets\n",
    "\n",
    "| column | format | source | description | Validation |\n",
    "| ------ | ------ | ---------- | ------------ | ------------- |\n",
    "| userid | bigint | Twitter API | User ID from above | FOREIGN KEY |\n",
    "| retweetid | bigint | Twitter API | Tweet ID for retweet | Integer, unique |\n",
    "| tweetid | bigint | Twitter API | Tweet ID for retweet | FOREIGN KEY |\n",
    "| createddate | datetime | Twitter API | Date with timestamp | Valid Datetime between May and September 2017 |\n",
    "\n",
    "### Replies\n",
    "\n",
    "| column | format | source | description | Validation |\n",
    "| ------ | ------ | ---------- | ------------ | ------------- |\n",
    "| tweetid | bigint | Twitter API | Tweet ID the user is replying to | FOREIGN KEY |\n",
    "| replyid | bigint | Twitter API | Tweet ID for reply | FOREIGN KEY |\n",
    "\n",
    "### Cashtags\n",
    "\n",
    "| column | format | source | description | Validation |\n",
    "| ------ | ------ | ---------- | ------------ | ------------- |\n",
    "| tweetid | bigint | Twitter API | Tweet ID the user is replying to | FOREIGN KEY |\n",
    "| symbolid | integer | securities | Cashtag Symbol | FOREIGN KEY |\n",
    "\n",
    "\n",
    "## From Tables to Tables:\n",
    "\n",
    "```\n",
    "CREATE TABLE IF NOT EXISTS symbols (\n",
    "  symbolid serial PRIMARY KEY,\n",
    "  nasdaqsymbol varchar NOT NULL,\n",
    "  securityname text NOT NULL\n",
    "  CONSTRAINT valid_symbol CHECK (nasdaqsymbol ~* '^[A-Z\\.\\=\\-\\+\\#\\^]+$')\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS stockvalues (\n",
    "    symbolid int REFERENCES symbols(symbolid),\n",
    "    date date CHECK (date >= '2017-05-01' AND date < '2017-10-01'),\n",
    "    open float CHECK (open > 0),\n",
    "    close float CHECK (close > 0)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    userid bigint PRIMARY KEY,\n",
    "    username text\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS tweets (\n",
    "    tweetid bigint PRIMARY KEY,\n",
    "    userid bigint REFERENCES users(userid),\n",
    "    tweet text NOT NULL,\n",
    "    createddate datetime NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS retweets (\n",
    "    userid bigint REFERENCES users(userid),\n",
    "    retweetid bigint NOT NULL PRIMARY KEY,\n",
    "    tweetid bigint REFERENCES tweets(tweetid),\n",
    "    createddate datetime NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS replies (\n",
    "    tweetid bigint REFERENCES tweets(tweetid),\n",
    "    replyid bigint REFERENCES tweets(tweetid) UNIQUE PRIMARY KEY\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS cashtags (\n",
    "    tweetid bigint REFERENCES tweets(tweetid),\n",
    "    symbolid int REFERENCES symbols(symbolid)\n",
    ");\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql\n",
    "%config SqlMagic.displaylimit = 20\n",
    "%config SqlMagic.autolimit = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "with open('credentials.json') as f:\n",
    "    login = json.load(f)\n",
    "    \n",
    "username = login['user']\n",
    "password = urllib.parse.quote(login['password'])\n",
    "host = login['host']\n",
    "port = login['port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "***1.  Identify elements of the potential dataset(s) that match each of the four Vs of Big Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.Velocity: the tweets, retweets, stock values data are generated in real-time, which are updated with high frequencies. Therefore, volocity is a essential aspect of this dataset.\n",
    "\n",
    "b.Veracity: the fact that a large amount of information in this dataset comes from user-generated tweets mean that they are prone to mistakes, misinformation and biases. The cashtag allows partial information from the tweets to be cross validated with official information from NYSE, but content such as sentiments can still hardly be verified. Moreover, as the information in tweets are stored as text data, the processing of such data is also prove to mistakes.\n",
    "\n",
    "c.Volume: this dataset contains a large scope of data involving tweets (including relevant retweets and cashtag information) and stocks (name and information, as well as price). The fact that this amount of information is updated in real time (again proving the velocity point) means that this dataset has high volume. \n",
    "\n",
    "d.Variety: the dataset contains multiple types of data, including structured data (e.g. numerical information such as tweetid and stock volume), unstructured data (e.g. text in tweets) and time series data (e.g. date and time information to track the creation time of tweets). Moreover, the use of foreign keys also highlight the interconnected nature between twitter data and stock data. The various types of data require different methods to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://{username}:{password}@{host}:{port}/postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@database-1.ctzujvaq0zsk.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>row_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6937668</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(6937668,)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select count(*) as row_count\n",
    "from tweets.cleantweets;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ask a question you want to answer on Twitter (the data you loaded in Question 2). Based on your question, create a mini-warehouse and proper indexing for the best performance for your query. Finally, explain the decisions you make.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Can spikes in Twitter mentions predict unusual stock price movements?\n",
    "\n",
    "Reasoning on how to resolve:\n",
    "This question aims to identify whether spikes in the volume of tweets mentioning a specific stock could result in price movements of that stock. The question could be addressed through the following sequence of steps:\n",
    "\n",
    "1. Identify spikes in twitter mentions: use the data to count the daily tweet counts of each stock, and define the threshold of spike as 1.5 times the 7-day moving average of twitter mentioning of a specific stock. Example queries for this step include grouping tweets by date and stock, computing the moving average, and flagging spikes.\n",
    "2. Measure stock price movements: look at stock price changes within the next available trading date. This timeframe is chose as the longer the timeframe, the less likely that the stock price changes are correlated with tweets. Therefore I wanted to investigate the immediate effects of the tweets on stock prices. Example queries in this step include calculating percentage price, change, join with tweets spike data. \n",
    "3. Check for correlations: after obtaining the above two information for each stock, compare the timing and see if the spikes in tweets happen before stock price changes (indicating potential predictive ability). Example queries in this step include computing the correlation between price change and tweet spikes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is the construction of my mini warehouse, and the reasoning behind is:\n",
    "1. the table tweet_counts needs to be created to store the daily tweets mentions per stock for ease of identifying spikes at later steps.\n",
    "2. the table stock_price_movements is built to record the changes in stock price over 3 days for each stock, so that in the next step we can more easily identify unusual stock price movements.\n",
    "3. the table tweet_spike_analysis is used to combine tweet spikes with stock price, so that a correlation could be inferred during later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@database-1.ctzujvaq0zsk.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS tweets.tweet_counts (\n",
    "    symbolid INT REFERENCES tweets.symbols(symbolid),\n",
    "    stock_symbol VARCHAR NOT NULL,\n",
    "    tweet_date DATE NOT NULL,\n",
    "    tweet_count INT CHECK (tweet_count >= 0),\n",
    "    PRIMARY KEY (symbolid, tweet_date)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS tweets.stock_price_movements (\n",
    "    symbolid INT REFERENCES tweets.symbols(symbolid),\n",
    "    stock_date DATE NOT NULL CHECK (stock_date >= '2017-05-01' AND stock_date < '2017-10-01'),\n",
    "    closing_price DOUBLE PRECISION CHECK (closing_price > 0),\n",
    "    next_trading_day DATE NOT NULL,\n",
    "    next_price_change DOUBLE PRECISION,\n",
    "    PRIMARY KEY (symbolid, stock_date)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS tweets.tweet_spike_analysis (\n",
    "    symbolid INT REFERENCES tweets.symbols(symbolid),\n",
    "    stock_symbol VARCHAR NOT NULL,\n",
    "    tweet_date DATE NOT NULL,\n",
    "    tweet_count INT,\n",
    "    moving_avg_tweets DOUBLE PRECISION,\n",
    "    spike_flag BOOLEAN,\n",
    "    next_price_change DOUBLE PRECISION,\n",
    "    PRIMARY KEY (symbolid, tweet_date)\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some composite indexes created to speed up the queries, as they improve filtering efficiency, join performance, and aggregation performance of later queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@database-1.ctzujvaq0zsk.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE INDEX idx_tweet_spike_analysis_composite \n",
    "ON tweets.tweet_spike_analysis (symbolid, tweet_date, next_price_change)\n",
    "WHERE spike_flag = TRUE;\n",
    "\n",
    "CREATE INDEX idx_stock_price_movements_composite \n",
    "ON tweets.stock_price_movements (symbolid, stock_date, next_trading_day);\n",
    "\n",
    "CREATE INDEX idx_tweet_counts_composite \n",
    "ON tweets.tweet_counts (symbolid, tweet_date, tweet_count);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below queries compute the daily tweet count per stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@database-1.ctzujvaq0zsk.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "251071 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO tweets.tweet_counts (symbolid, stock_symbol, tweet_date, tweet_count)\n",
    "SELECT \n",
    "    c.symbolid,  \n",
    "    s.nasdaqsymbol AS stock_symbol,\n",
    "    DATE(t.createdate) AS tweet_date,\n",
    "    COUNT(t.tweetid) AS tweet_count\n",
    "FROM tweets.cleantweets t\n",
    "JOIN tweets.cashtags c ON t.tweetid = c.tweetid\n",
    "JOIN tweets.symbols s ON c.symbolid = s.symbolid\n",
    "GROUP BY c.symbolid, s.nasdaqsymbol, DATE(t.createdate);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The below queries compute the stock price movements for the next available trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@database-1.ctzujvaq0zsk.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "361581 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO tweets.stock_price_movements (symbolid, stock_date, closing_price, next_trading_day, next_price_change)\n",
    "WITH next_trading_day_prices AS (\n",
    "    SELECT \n",
    "        s1.symbolid,\n",
    "        s1.date AS stock_date,\n",
    "        s1.close AS closing_price,\n",
    "        MIN(s2.date) AS next_trading_day\n",
    "    FROM tweets.stockvalues s1\n",
    "    LEFT JOIN tweets.stockvalues s2 \n",
    "        ON s1.symbolid = s2.symbolid \n",
    "        AND s2.date > s1.date\n",
    "    WHERE s2.date IS NOT NULL  \n",
    "    GROUP BY s1.symbolid, s1.date, s1.close\n",
    ")\n",
    "SELECT \n",
    "    ntd.symbolid,\n",
    "    ntd.stock_date,\n",
    "    ntd.closing_price,\n",
    "    ntd.next_trading_day,\n",
    "    (s3.close - ntd.closing_price) / ntd.closing_price * 100 AS next_price_change\n",
    "FROM next_trading_day_prices ntd\n",
    "LEFT JOIN tweets.stockvalues s3 \n",
    "    ON ntd.symbolid = s3.symbolid \n",
    "    AND ntd.next_trading_day = s3.date;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to detect any tweet spikes (1.5 times the 7 day moving average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@database-1.ctzujvaq0zsk.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "251071 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO tweets.tweet_spike_analysis \n",
    "(symbolid, stock_symbol, tweet_date, tweet_count, moving_avg_tweets, spike_flag, next_price_change)\n",
    "WITH moving_avg AS (\n",
    "    SELECT \n",
    "        symbolid,\n",
    "        tweet_date,\n",
    "        tweet_count,\n",
    "        AVG(tweet_count) OVER (PARTITION BY symbolid ORDER BY tweet_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_tweets\n",
    "    FROM tweets.tweet_counts\n",
    "),\n",
    "valid_trading_day AS (\n",
    "    SELECT t.symbolid, t.tweet_date, \n",
    "        MIN(s.stock_date) AS next_trading_day\n",
    "    FROM tweets.tweet_counts t\n",
    "    JOIN tweets.stock_price_movements s \n",
    "    ON t.symbolid = s.symbolid AND s.stock_date > t.tweet_date\n",
    "    GROUP BY t.symbolid, t.tweet_date\n",
    ")\n",
    "SELECT \n",
    "    m.symbolid,\n",
    "    t.stock_symbol,\n",
    "    m.tweet_date,\n",
    "    m.tweet_count,\n",
    "    m.moving_avg_tweets,\n",
    "    CASE \n",
    "        WHEN m.tweet_count > 1.5 * m.moving_avg_tweets THEN TRUE \n",
    "        ELSE FALSE \n",
    "    END AS spike_flag,\n",
    "    s.next_price_change\n",
    "FROM moving_avg m\n",
    "JOIN tweets.tweet_counts t \n",
    "    ON m.symbolid = t.symbolid  \n",
    "    AND m.tweet_date = t.tweet_date\n",
    "LEFT JOIN tweets.stock_price_movements s \n",
    "    ON m.symbolid = s.symbolid  \n",
    "    AND m.tweet_date = s.stock_date;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the correlation analysis are run. Only stocks with correlation coefficients are displayed because lots of stocks are missing stock prices for the next immediate date following the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@database-1.ctzujvaq0zsk.us-east-1.rds.amazonaws.com:5432/postgres\n",
      "2691 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>stock_symbol</th>\n",
       "        <th>spike_count</th>\n",
       "        <th>avg_next_price_change</th>\n",
       "        <th>correlation_coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>XHE</td>\n",
       "        <td>2</td>\n",
       "        <td>-0.05022854489892442</td>\n",
       "        <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>EMQQ</td>\n",
       "        <td>2</td>\n",
       "        <td>0.2100919787757751</td>\n",
       "        <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>PRG</td>\n",
       "        <td>2</td>\n",
       "        <td>0.6357567718767551</td>\n",
       "        <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>UZA</td>\n",
       "        <td>2</td>\n",
       "        <td>-0.5418549373228769</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>IHIT</td>\n",
       "        <td>2</td>\n",
       "        <td>0.10564215201379422</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SPYV</td>\n",
       "        <td>2</td>\n",
       "        <td>0.6383611905801052</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>IWP</td>\n",
       "        <td>2</td>\n",
       "        <td>0.7445060497068248</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>IWY</td>\n",
       "        <td>2</td>\n",
       "        <td>0.11205318965679262</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>XHS</td>\n",
       "        <td>2</td>\n",
       "        <td>0.44316806958727295</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>JBGS</td>\n",
       "        <td>2</td>\n",
       "        <td>-2.136128109714025</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ACWV</td>\n",
       "        <td>2</td>\n",
       "        <td>0.3632544488811907</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AOR</td>\n",
       "        <td>2</td>\n",
       "        <td>-0.08954887843234437</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>DBE</td>\n",
       "        <td>2</td>\n",
       "        <td>0.8439685158087036</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>GOAU</td>\n",
       "        <td>2</td>\n",
       "        <td>0.20082374939163414</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SKF</td>\n",
       "        <td>2</td>\n",
       "        <td>0.7942025471342401</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>GMF</td>\n",
       "        <td>2</td>\n",
       "        <td>0.14145093319544197</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>MHD</td>\n",
       "        <td>2</td>\n",
       "        <td>0.1993751804537922</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>PXE</td>\n",
       "        <td>2</td>\n",
       "        <td>2.2350830660307692</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>GLTR</td>\n",
       "        <td>2</td>\n",
       "        <td>-0.40955396177396725</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>REW</td>\n",
       "        <td>2</td>\n",
       "        <td>0.3548820083859039</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<span style=\"font-style:italic;text-align:center;\">30 rows, truncated to displaylimit of 20</span>"
      ],
      "text/plain": [
       "[('XHE', 2, -0.05022854489892442, 1.0000000000000002),\n",
       " ('EMQQ', 2, 0.2100919787757751, 1.0000000000000002),\n",
       " ('PRG', 2, 0.6357567718767551, 1.0000000000000002),\n",
       " ('UZA', 2, -0.5418549373228769, 1.0),\n",
       " ('IHIT', 2, 0.10564215201379422, 1.0),\n",
       " ('SPYV', 2, 0.6383611905801052, 1.0),\n",
       " ('IWP', 2, 0.7445060497068248, 1.0),\n",
       " ('IWY', 2, 0.11205318965679262, 1.0),\n",
       " ('XHS', 2, 0.44316806958727295, 1.0),\n",
       " ('JBGS', 2, -2.136128109714025, 1.0),\n",
       " ('ACWV', 2, 0.3632544488811907, 1.0),\n",
       " ('AOR', 2, -0.08954887843234437, 1.0),\n",
       " ('DBE', 2, 0.8439685158087036, 1.0),\n",
       " ('GOAU', 2, 0.20082374939163414, 1.0),\n",
       " ('SKF', 2, 0.7942025471342401, 1.0),\n",
       " ('GMF', 2, 0.14145093319544197, 1.0),\n",
       " ('MHD', 2, 0.1993751804537922, 1.0),\n",
       " ('PXE', 2, 2.2350830660307692, 1.0),\n",
       " ('GLTR', 2, -0.40955396177396725, 1.0),\n",
       " ('REW', 2, 0.3548820083859039, 1.0),\n",
       " ('SHE', 2, 0.1105375674274644, 1.0),\n",
       " ('MGK', 2, 0.3939209868543602, 1.0),\n",
       " ('VFL', 2, 0.22173550320670693, 1.0),\n",
       " ('GJS', 2, 0.12986811474987084, 1.0),\n",
       " ('SCHR', 2, -0.046087176329559415, 1.0),\n",
       " ('RPG', 2, -0.24709209275492733, 1.0),\n",
       " ('IAI', 2, 0.5100547941717612, 1.0),\n",
       " ('PBD', 2, 0.39033666377410375, 1.0),\n",
       " ('EWK', 2, 0.8159223633735584, 1.0),\n",
       " ('CAPE', 2, 0.2428019273375591, 1.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    stock_symbol,\n",
    "    COUNT(*) AS spike_count,\n",
    "    AVG(next_price_change) AS avg_next_price_change,\n",
    "    CORR(tweet_count, next_price_change) AS correlation_coefficient\n",
    "FROM tweets.tweet_spike_analysis\n",
    "WHERE spike_flag = TRUE\n",
    "AND next_price_change IS NOT NULL\n",
    "GROUP BY stock_symbol\n",
    "HAVING CORR(tweet_count, next_price_change) IS NOT NULL\n",
    "ORDER BY correlation_coefficient DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bait580_2024]",
   "language": "python",
   "name": "conda-env-bait580_2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
